Deploying an Application with Helm and Integrating Prometheus Monitoring
To deploy an application using Helm and set up Prometheus monitoring, follow these steps:

1. Prerequisites
Kubernetes Cluster: Ensure you have a running Kubernetes cluster.
Helm Installed: Install Helm on your local machine (helm version to confirm).
Prometheus Operator: Ensure Prometheus is deployed in your cluster (e.g., via the kube-prometheus-stack Helm chart).
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack
#####################################
2. Create Helm Chart for Your Application
Generate Helm Chart:

helm create my-app
cd my-app

Define Deployment and Service: Update the templates/deployment.yaml and templates/service.yaml to define your application.
#########################
# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-nginx
  labels:
    app: {{ .Release.Name }}-nginx
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-nginx
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-nginx
    spec:
      containers:
        - name: nginx
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 80
          resources:
            limits:
              cpu: {{ .Values.resources.limits.cpu }}
              memory: {{ .Values.resources.limits.memory }}
            requests:
              cpu: {{ .Values.resources.requests.cpu }}
              memory: {{ .Values.resources.requests.memory }}
##########################################
service.yaml:

# templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-nginx
  labels:
    app: {{ .Release.Name }}-nginx
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 80
  selector:
    app: {{ .Release.Name }}-nginx


###############################################
#Values.yml
replicaCount: 2

image:
  repository: nginx
  tag: "1.25.2"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

resources:
  limits:
    cpu: "500m"
    memory: "256Mi"
  requests:
    cpu: "200m"
    memory: "128Mi"

ingress:
  enabled: false

nodeSelector: {}
tolerations: []
affinity: {}


############################################
3. Add Prometheus Integration
Expose Metrics in the Application: Ensure your application exposes metrics at a /metrics endpoint using a Prometheus client library (e.g., for Python, Java, etc.).

Add a ServiceMonitor: Create a ServiceMonitor resource in the Helm chart to enable Prometheus scraping.

templates/servicemonitor.yaml:
##################################################

Ensure the Prometheus Operator is configured to discover ServiceMonitors with the release: prometheus label.
######################################################
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {{ .Release.Name }}-nginx-monitor
  labels:
    release: {{ .Release.Name }}
    app: nginx
spec:
  selector:
    matchLabels:
      app: nginx
      release: {{ .Release.Name }}
  endpoints:
    - port: http
      interval: 30s
      path: /metrics
      scheme: http
######################################################
4. Deploy the Helm Chart
Package and Install the Chart:

helm package .
helm install my-app ./my-app
Verify Deployment:

kubectl get pods
kubectl get servicemonitor
########################################################
5. View Metrics in Prometheus and Grafana
Access Prometheus Targets:

Navigate to the Prometheus UI: http://<prometheus-url>:9090.
Check if your application appears under Targets.
View Metrics in Grafana:

Add Prometheus as a data source in Grafana.
Create a dashboard to visualize your application metrics.
Final Notes
Ensure the ServiceMonitor labels match Prometheus' configuration for target discovery.
Use Grafana for better visualization and dashboards.
Regularly validate the /metrics endpoint to ensure it exposes meaningful metrics for monitoring.

########################################################

1. Install FastAPI and Prometheus Client

sudo apt update -y
sudo apt install -y python3-pip
pip3 install fastapi uvicorn prometheus-client
âœ… 2. Create FastAPI App with Prometheus Metrics
Create a file named main.py:

from fastapi import FastAPI
from prometheus_client import Counter, generate_latest
from fastapi.responses import Response

app = FastAPI()

REQUEST_COUNT = Counter("request_count", "Total number of requests")

@app.get("/")
def read_root():
    REQUEST_COUNT.inc()
    return {"message": "Hello, World"}

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type="text/plain")
âœ… 3. Run the App on Port 8000

uvicorn main:app --host 0.0.0.0 --port 8000
or
python3 -m uvicorn main:app --host 0.0.0.0 --port 8000
âœ… 4. Configure Prometheus to Scrape FastAPI Metrics
Edit Prometheus config:


sudo vim /etc/prometheus/prometheus.yml
Add this job under scrape_configs:


  - job_name: 'ml_model'
    static_configs:
      - targets: ['localhost:8000']
Make sure indentation is correct. This goes under scrape_configs: list.

Example:


scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'ml_model'
    static_configs:
      - targets: ['localhost:8000']
âœ… 5. Restart Prometheus

sudo systemctl restart prometheus
âœ… 6. Verify Setup
Go to http://localhost:8000/metrics â†’ should return Prometheus-formatted metrics.

Open Prometheus at http://localhost:9090 and search for the metric request_count.


âœ… Step-by-Step: Add Prometheus to Grafana
ðŸ”¹ 1. Install Grafana (if not already installed)

sudo apt update -y
sudo apt install -y software-properties-common
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
sudo apt update -y
sudo apt install -y grafana
sudo systemctl enable --now grafana-server
Access Grafana: http://localhost:3000

Default login

Username: admin

Password: admin (will prompt to change)

ðŸ”¹ 2. Add Prometheus as a Data Source
Open Grafana in browser â†’ http://localhost:3000

Go to Settings (Gear icon) > Data Sources

Click Add Data Source

Choose Prometheus

In the HTTP URL, enter:


http://localhost:9090
Click Save & Test â†’ It should say "Data source is working"

ðŸ”¹ 3. Create a Dashboard with Prometheus Metrics
Go to Dashboards > New Dashboard

Click Add a new panel

In the Query box, use your metric:


request_count
Adjust visualization type (e.g., Time series or Stat panel)

Click Apply to save the panel

Save the dashboard with a name like "ML Model Monitoring"
####################################################################
